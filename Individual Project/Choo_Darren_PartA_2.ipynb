{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7e82aadc4d77a8b23f7f880449f9e3",
     "grade": false,
     "grade_id": "a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb28aa752ce5540f5b18d10694b52ea9",
     "grade": false,
     "grade_id": "a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    "* note: some cells are non-editable and cannot be filled, but leave them untouched. Fill up only cells which are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aceec82011f43733c0551ca196f1b16c",
     "grade": false,
     "grade_id": "a2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0edc610-21e6-4cc7-9603-59318b961990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909acb3c7ff3883eb5381eb586615d3b",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e12861-4713-4914-9f4b-8a7381708243",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed97d9f30da032a5e349047c614efec1",
     "grade": false,
     "grade_id": "a2_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a1a982-de85-46de-b890-3b81f79f5887",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db3ca972642b1447dba3ebd5f2db24b",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import MLP, CustomDataset, loss_fn, preprocess_dataset, EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae6b33318200b4bc38d431576963edb1",
     "grade": true,
     "grade_id": "correct_import",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c738d3b4888de90dda8c532036bc5fe5",
     "grade": false,
     "grade_id": "a2_1_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3. Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
   "metadata": {
    "deletable": false,
    "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02dac62baa528c191eb4f47b2495406",
     "grade": false,
     "grade_id": "dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = {},{},{},{}  #creating our dictionaries to return\n",
    "\n",
    "\n",
    "    cv = KFold(n_splits = 5, shuffle=False)\n",
    "\n",
    "\n",
    "    for batch_size in parameters:\n",
    "\n",
    "        #initialising the values of the keys (batch size) in the dictionary as lists\n",
    "        X_train_scaled_dict[batch_size] = []\n",
    "        X_val_scaled_dict[batch_size] = []\n",
    "        y_train_dict[batch_size] = []\n",
    "        y_val_dict[batch_size] = []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "            x_train_fold, y_train_fold  = X_train[train_idx], y_train[train_idx]\n",
    "            x_val_fold, y_val_fold = X_train[val_idx], y_train[val_idx]\n",
    "\n",
    "            #scaling X values using preprocess_dataset() function is common_utils\n",
    "            x_train_scaled_fold, x_val_scaled_fold = preprocess_dataset(x_train_fold, x_val_fold)\n",
    "\n",
    "            X_train_scaled_dict[batch_size].append(x_train_scaled_fold)\n",
    "            X_val_scaled_dict[batch_size].append(x_val_scaled_fold)\n",
    "            y_train_dict[batch_size].append(y_train_fold)\n",
    "            y_val_dict[batch_size].append(y_val_fold)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "\n",
    "#obtaining our X_train and y_train\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "df['label'] = label_encoder.fit_transform(df['label'])  #changing the labels from neg/pos to 1/0\n",
    "\n",
    "y = df['label'].to_numpy()\n",
    "X = df.drop([\"filename\",\"label\"], axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)\n",
    "\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ca332-9676-42bd-9801-0f5f4157a777",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "235ca332-9676-42bd-9801-0f5f4157a777",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ae5f281cd84f4d36f81f2ae126cf915",
     "grade": true,
     "grade_id": "correct_dataset",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dcf6be1ad49306172e6f27243e613f2",
     "grade": true,
     "grade_id": "correct_dataset2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d68c9708b5e3f1e2463001b6d78b4",
     "grade": false,
     "grade_id": "a2_1_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4. Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9665887943f38ae7bed6c1d8351903b",
     "grade": true,
     "grade_id": "hyperparameter_tuning",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "b9441831-5dd8-442a-d2c1-3aa924bc29f2",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size:  128\n",
      "Fold  1\n",
      "Early stopped at 37!\n",
      "Last epoch accuracy value:  0.7067535545023697\n",
      "Last epoch time taken:  0.6548237800598145\n",
      "Fold  2\n",
      "Early stopped at 13!\n",
      "Last epoch accuracy value:  0.6492890995260664\n",
      "Last epoch time taken:  0.6780707836151123\n",
      "Fold  3\n",
      "Early stopped at 21!\n",
      "Last epoch accuracy value:  0.6605450236966824\n",
      "Last epoch time taken:  0.667773962020874\n",
      "Fold  4\n",
      "Early stopped at 18!\n",
      "Last epoch accuracy value:  0.6800947867298578\n",
      "Last epoch time taken:  0.21999478340148926\n",
      "Fold  5\n",
      "Early stopped at 25!\n",
      "Last epoch accuracy value:  0.6769413159454654\n",
      "Last epoch time taken:  0.670621395111084\n",
      "\n",
      "Mean CV accuracy for batch size 128: 0.6747247560800883\n",
      "Mean time taken to train network on last epoch for batch size 128: 0.5782569408416748 \n",
      "\n",
      "----------------------------------------\n",
      "Batch_size:  256\n",
      "Fold  1\n",
      "Early stopped at 34!\n",
      "Last epoch accuracy value:  0.6877962085308057\n",
      "Last epoch time taken:  0.5024075508117676\n",
      "Fold  2\n",
      "Early stopped at 80!\n",
      "Last epoch accuracy value:  0.7008293838862559\n",
      "Last epoch time taken:  0.5328943729400635\n",
      "Fold  3\n",
      "Early stopped at 12!\n",
      "Last epoch accuracy value:  0.6338862559241706\n",
      "Last epoch time taken:  0.5268344879150391\n",
      "Fold  4\n",
      "Early stopped at 34!\n",
      "Last epoch accuracy value:  0.6872037914691943\n",
      "Last epoch time taken:  0.533740758895874\n",
      "Fold  5\n",
      "Early stopped at 30!\n",
      "Last epoch accuracy value:  0.6745702430349734\n",
      "Last epoch time taken:  0.5130939483642578\n",
      "\n",
      "Mean CV accuracy for batch size 256: 0.67685717656908\n",
      "Mean time taken to train network on last epoch for batch size 256: 0.5217942237854004 \n",
      "\n",
      "----------------------------------------\n",
      "Batch_size:  512\n",
      "Fold  1\n",
      "Early stopped at 58!\n",
      "Last epoch accuracy value:  0.6800947867298578\n",
      "Last epoch time taken:  0.4011685848236084\n",
      "Fold  2\n",
      "Early stopped at 76!\n",
      "Last epoch accuracy value:  0.7156398104265402\n",
      "Last epoch time taken:  0.20913171768188477\n",
      "Fold  3\n",
      "Early stopped at 82!\n",
      "Last epoch accuracy value:  0.7043838862559242\n",
      "Last epoch time taken:  0.12960267066955566\n",
      "Fold  4\n",
      "Early stopped at 74!\n",
      "Last epoch accuracy value:  0.6937203791469194\n",
      "Last epoch time taken:  0.13151335716247559\n",
      "Fold  5\n",
      "Early stopped at 79!\n",
      "Last epoch accuracy value:  0.6893894487255483\n",
      "Last epoch time taken:  0.1430041790008545\n",
      "\n",
      "Mean CV accuracy for batch size 512: 0.6966456622569581\n",
      "Mean time taken to train network on last epoch for batch size 512: 0.20288410186767578 \n",
      "\n",
      "----------------------------------------\n",
      "Batch_size:  1024\n",
      "Fold  1\n",
      "Last epoch accuracy value:  0.7037914691943128\n",
      "Last epoch time taken:  0.11999964714050293\n",
      "Fold  2\n",
      "Last epoch accuracy value:  0.6943127962085308\n",
      "Last epoch time taken:  0.11534452438354492\n",
      "Fold  3\n",
      "Last epoch accuracy value:  0.7091232227488151\n",
      "Last epoch time taken:  0.1179502010345459\n",
      "Fold  4\n",
      "Last epoch accuracy value:  0.716824644549763\n",
      "Last epoch time taken:  0.11385178565979004\n",
      "Fold  5\n",
      "Last epoch accuracy value:  0.7148784825133373\n",
      "Last epoch time taken:  0.2200009822845459\n",
      "\n",
      "Mean CV accuracy for batch size 1024: 0.7077861230429517\n",
      "Mean time taken to train network on last epoch for batch size 1024: 0.13742942810058595 \n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "#using the same settings as our model in A1\n",
    "no_features = 77\n",
    "no_hidden = 128\n",
    "no_labels = 2\n",
    "lr = 0.001\n",
    "no_epochs = 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#implementing train loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, correct = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        y_long = y.type(torch.LongTensor)\n",
    "        loss = loss_fn(pred, y_long)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()  #initialize gradient calculations\n",
    "        loss.backward()  #compute gradients\n",
    "        optimizer.step()  #take one step of SGD\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= size\n",
    "    correct /= size\n",
    "    return train_loss, correct\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#implementing test loop\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            y_long = y.type(torch.LongTensor)\n",
    "            test_loss += loss_fn(pred, y_long).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    return test_loss, correct\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, mode):\n",
    "\n",
    "    fold = [0,1,2,3,4] #index for our 5-folds\n",
    "\n",
    "    cv_accuracies = [] #this is contain the 4 mean accuracy values for the 4 batch sizes\n",
    "    cv_times = [] #this contains the time taken to train the network on the last epoch\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        print(\"Batch_size: \", batch_size)\n",
    "\n",
    "        batchFoldAcc = []  #this is to contain the 5 accuracy values of the last epoch, for the 5-folds, which we will take the mean after\n",
    "        batchFoldTime = []  #this is to contain the 5 time taken to train the network for the last epoch, for the 5-folds, which we will take the mean after\n",
    "\n",
    "        #looping through folds\n",
    "        for idx in fold:\n",
    "            print(\"Fold \", idx+1)\n",
    "\n",
    "            train_data = CustomDataset(X_train_scaled_dict[batch_size][idx], y_train_dict[batch_size][idx])\n",
    "            val_data = CustomDataset(X_val_scaled_dict[batch_size][idx], y_val_dict[batch_size][idx])\n",
    "\n",
    "            train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "            val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "            model = MLP(no_features, no_hidden, no_labels)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "            #initialising early stopper for each fold before we begin training\n",
    "            early_stopper = EarlyStopper(min_delta = 0.00005) #min_delta = 0.00005\n",
    "            early_stopper_bool = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for epoch in range(no_epochs):\n",
    "                t = 0\n",
    "\n",
    "                #start time\n",
    "                start_time = time.time()\n",
    "\n",
    "                train_loss, train_acc = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "                val_loss, val_acc = test_loop(val_dataloader, model, loss_fn)\n",
    "\n",
    "                t += time.time() - start_time\n",
    "\n",
    "                #early stopper used on val_loss\n",
    "                early_stopper_bool = early_stopper.early_stop(val_loss)\n",
    "                if early_stopper_bool:\n",
    "                    print(f\"Early stopped at {epoch+1}!\")\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(\"Last epoch accuracy value: \", val_acc)\n",
    "            batchFoldAcc.append(val_acc) #appending the last epoch accuracy value of each fold to the list\n",
    "\n",
    "            print(\"Last epoch time taken: \", t)\n",
    "            batchFoldTime.append(t) #appending last epoch time of each fold to the list\n",
    "\n",
    "\n",
    "\n",
    "        meanAcc = np.mean(batchFoldAcc) #obtaining the mean cv accuracy\n",
    "        print(f\"\\nMean CV accuracy for batch size {batch_size}: {meanAcc}\")\n",
    "\n",
    "        meanTime = np.mean(batchFoldTime) #obtaining the mean time\n",
    "        print(f\"Mean time taken to train network on last epoch for batch size {batch_size}: {meanTime} \\n\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "        cv_accuracies.append(meanAcc)\n",
    "        cv_times.append(meanTime)\n",
    "\n",
    "    return cv_accuracies, cv_times\n",
    "\n",
    "\n",
    "\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, 'batch_size')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975e552e751c4efb2cec0eac214f85cd",
     "grade": true,
     "grade_id": "correct_hyperparameter_tuning",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69421943e22521de848bb03a50f57767",
     "grade": false,
     "grade_id": "a2_1_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "5. Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17599eb29fd6e3a1e2812f0ff7cba983",
     "grade": true,
     "grade_id": "plot",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "1474ba04-1f04-4f9c-810d-3102b1e14980",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(batch_sizes, cross_validation_accuracies, marker = 'x', linestyle = 'None')\n",
    "plt.xticks(batch_sizes)\n",
    "plt.xlabel('batch size number')\n",
    "plt.ylabel('mean cv accuracies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e8d298b5774c4044f1c3f950c46214",
     "grade": false,
     "grade_id": "a2_1_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "6. Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "deletable": false,
    "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18e30a9850c282ad725336848222a62",
     "grade": false,
     "grade_id": "times",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "ee640372-2372-426b-8415-414ed0bb326d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Last Epoch Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.578257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.521794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.202884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.137429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Last Epoch Time\n",
       "0         128         0.578257\n",
       "1         256         0.521794\n",
       "2         512         0.202884\n",
       "3        1024         0.137429"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Batch Size': batch_sizes,\n",
    "                   'Last Epoch Time': cross_validation_times\n",
    "                  })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2fc4a52c2a0af7ea586ea85cec9b3e9",
     "grade": true,
     "grade_id": "correct_times",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
   "metadata": {
    "deletable": false,
    "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38690f32ec506325fc73c8353b77d041",
     "grade": false,
     "grade_id": "batch_size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 1024\n",
    "reason = \"This batch size provided the highest Mean CV Accuracy while having the shortest last epoch timing too. We notice that\\\n",
    "as batch size increases, the epochs where early stopping kicked in also increases. There was no early stopping during the\\\n",
    "training for batch size = 1024. This suggest that there was no overfitting and thus i selected it as the optimal batch size.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f695b961ed43ec6a31b7647e078fd8d6",
     "grade": true,
     "grade_id": "correct_batch_size",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
